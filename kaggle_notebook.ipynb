{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MediTranslator v3 En‚ÜíVi LoRA Training\n",
    "\n",
    "This notebook fine-tunes the v3_en2vi model using LoRA (Low-Rank Adaptation) for efficient parameter-efficient English‚ÜíVietnamese medical text translation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install Dependencies\n",
    "!pip install -q torch torchaudio torchvision\n",
    "!pip install -q wandb pyyaml tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Clone Repository\n",
    "import os\n",
    "\n",
    "# Clone the transformer-v3 repo (which is the MediTranslator project)\n",
    "if not os.path.exists('MediTranslator'):\n",
    "    !git clone https://github.com/aCoderChild/transformer-v3.git MediTranslator\n",
    "\n",
    "%cd MediTranslator\n",
    "print('Repository cloned successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Setup Data Paths\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üì• SETTING UP DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Use absolute paths to avoid working directory issues\n",
    "MEDI_REPO = '/kaggle/working/MediTranslator'\n",
    "DATA_INPUT = '/kaggle/input/mediatranslator-training-data'\n",
    "DATA_OUTPUT = os.path.join(MEDI_REPO, 'data', 'raw')\n",
    "\n",
    "# First, verify input exists\n",
    "if not os.path.exists(DATA_INPUT):\n",
    "    print(f\"\\n‚ùå ERROR: Input dataset not found at {DATA_INPUT}\")\n",
    "    print(f\"   Make sure 'mediatranslator-training-data' is connected in Kaggle Input\")\n",
    "else:\n",
    "    print(f\"\\n‚úì Input dataset found: {DATA_INPUT}\")\n",
    "    input_files = os.listdir(DATA_INPUT)\n",
    "    print(f\"  Files available: {input_files}\")\n",
    "\n",
    "# Create output directory with absolute path\n",
    "os.makedirs(DATA_OUTPUT, exist_ok=True)\n",
    "print(f\"\\n‚úì Output directory created: {DATA_OUTPUT}\")\n",
    "\n",
    "# Copy training data files\n",
    "files = ['train.en.txt', 'train.vi.txt', 'public_test.en.txt', 'public_test.vi.txt']\n",
    "\n",
    "print(f\"\\nüìã Copying files:\")\n",
    "for file in files:\n",
    "    src = os.path.join(DATA_INPUT, file)\n",
    "    dst = os.path.join(DATA_OUTPUT, file)\n",
    "    \n",
    "    if not os.path.exists(src):\n",
    "        print(f\"  ‚úó {file} - NOT FOUND in input\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        shutil.copy2(src, dst)\n",
    "        size = os.path.getsize(dst) / 1024 / 1024\n",
    "        print(f\"  ‚úì {file} ({size:.2f} MB)\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó {file} - ERROR: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Data setup complete!\")\n",
    "print(f\"Files in {DATA_OUTPUT}:\")\n",
    "if os.path.exists(DATA_OUTPUT):\n",
    "    for f in os.listdir(DATA_OUTPUT):\n",
    "        full_path = os.path.join(DATA_OUTPUT, f)\n",
    "        size = os.path.getsize(full_path) / 1024 / 1024\n",
    "        print(f\"  ‚úì {f} ({size:.2f} MB)\")\n",
    "else:\n",
    "    print(f\"  ‚úó Directory not found\")\n",
    "\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3.5: Verify Data Setup\n",
    "import os\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üîç VERIFYING DATA SETUP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check if data/raw directory exists and has files\n",
    "data_raw_dir = './data/raw'\n",
    "print(f\"\\n‚úì Checking: {data_raw_dir}\")\n",
    "\n",
    "if os.path.exists(data_raw_dir):\n",
    "    files_in_raw = os.listdir(data_raw_dir)\n",
    "    print(f\"  ‚úì Directory exists\")\n",
    "    print(f\"  ‚úì Files found: {len(files_in_raw)}\")\n",
    "    for f in files_in_raw:\n",
    "        size_mb = os.path.getsize(os.path.join(data_raw_dir, f)) / (1024**2)\n",
    "        print(f\"    - {f} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    # Check for required files\n",
    "    required_files = ['train.en.txt', 'train.vi.txt', 'public_test.en.txt', 'public_test.vi.txt']\n",
    "    missing = [f for f in required_files if f not in files_in_raw]\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"\\n‚ö†Ô∏è  Missing files: {missing}\")\n",
    "        print(f\"   Please re-run Cell 3 to copy them\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ All required files present!\")\n",
    "else:\n",
    "    print(f\"  ‚úó Directory does not exist\")\n",
    "    print(f\"  Please run Cell 3 first to set up data\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Login to W&B (for tracking)\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "# W&B API key for tracking\n",
    "WANDB_API_KEY = \"445d8df72343591d6588f101349ad4752497ce62\"\n",
    "\n",
    "os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n",
    "wandb.login(key=WANDB_API_KEY, anonymous=\"never\")\n",
    "print('‚úÖ Logged in to W&B! Loss will be tracked.')\n",
    "print('View your training at: https://wandb.ai/joshuafoshua-university-of-engineering-and-technology-hanoi/nlp-transformer-mt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.5: Setup Checkpoint Backup (Google Drive if running in Colab)\n",
    "import os\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üì§ SETTING UP CHECKPOINT BACKUP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Try to mount Google Drive if running in Colab\n",
    "DRIVE_AVAILABLE = False\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    DRIVE_AVAILABLE = True\n",
    "    print(\"\\n‚úì Google Drive mounted successfully!\")\n",
    "    print(\"  Checkpoints will auto-save to: Google Drive/MediTranslator_Checkpoints/\")\n",
    "except:\n",
    "    print(\"\\n‚ö†Ô∏è  Not running in Colab (this is fine)\")\n",
    "    print(\"  Checkpoints will save to local computer or Kaggle output\")\n",
    "\n",
    "# Setup local backup directory\n",
    "local_backup = os.path.expanduser(\"~/MediTranslator_Backups\")\n",
    "print(f\"\\n  Local backup directory: {local_backup}\")\n",
    "\n",
    "print(\"\\n‚úì Backup setup complete!\")\n",
    "print(\"  During training, checkpoints will be saved to:\")\n",
    "print(\"    1. Local computer (preferred)\")\n",
    "print(\"    2. Google Drive (if Colab + mounted)\")\n",
    "print(\"    3. Kaggle output (if running on Kaggle)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Monitor LoRA Training Progress (Run While Training)\n",
    "\n",
    "**LoRA Checkpoints are being saved to your local experiments folder DURING training!**\n",
    "\n",
    "Run this cell while training is happening to see checkpoints appear in real-time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ú® SUMMARY:\")\n",
    "print(\"=\" * 70)\n",
    "if local_ckpts:\n",
    "    print(f\"‚úÖ Checkpoints ARE being saved during training!\")\n",
    "    print(f\"   Latest: {os.path.basename(local_ckpts[-1])}\")\n",
    "    print(f\"   Ready to use or download from Kaggle Output tab\")\n",
    "else:\n",
    "    print(f\"‚è≥ Training in progress...\")\n",
    "    print(f\"   First checkpoint will appear after 500 steps\")\n",
    "    print(f\"   Checkpoints saved every 500 training steps automatically\")\n",
    "    print(f\"   Run this cell again to see updates!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Complete!\n",
    "\n",
    "Checkpoints saved to: `experiments/v3_en2vi/checkpoints/`\n",
    "\n",
    "Logs available at: `experiments/v3_en2vi/logs/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
